paleta='red'
demoTableRelPlot=barplot(demoTableRel,main=title,
col=paleta,ylim = c(0,100),
ylab = "%")
###
ecoTable=table(dataidx[,3])
names(ecoTable)=level5
ecoTableRel=round(prop.table(ecoTable)*100,1)
title='Libertad Económica'
paleta='red'
barplot(ecoTableRel,main=title,
col=paleta,ylim = c(0,100),
ylab = "%")
#####
worldTable=table(dataidx[,2])
names(worldTable)=level3
worldTableRel=round(prop.table(worldTable)*100,1)
title='Libertad en el Mundo'
paleta='red'
barplot(worldTableRel,main=title,
col=paleta,ylim = c(0,100),
ylab = "%")
####
pressTable=table(dataidx[,4])
names(pressTable)=level5
pressTableRel=round(prop.table(pressTable)*100,1)
title='Libertad de Prensa'
paleta='red'
barplot(pressTableRel,main=title,
col=paleta,ylim = c(0,100),
ylab = "%",las=2)
# Chunk 4: summary
library(stargazer)
vars1 <- dataidx[, c(2:5)]
stargazer(vars1,title = "Medidas estadísticas", label = "stats",summary.stat = c("n", "median"))
# Chunk 5: corrDem
explanans=names(dataidx)[c(2:4)]
corrDem=cor(dataidx[,5],dataidx[,explanans],
use = "na.or.complete")
stargazer(corrDem, title="Correlación de Democracia con las demás variables",label = "corrDem")
# Chunk 6: corrTableX
corrTableX=round(cor(dataidx[explanans],
use = "na.or.complete"),2)
corrTableX_copy=corrTableX
# Hide upper triangle
corrTableX[upper.tri(corrTableX)]<-""
stargazer(corrTableX, title="Correlación entre variables independientes",label = 'corrTableX')
# Chunk 7: corrPlotX
library(corrplot)
corrplot(corrTableX_copy, type = "lower", diag = F,
addCoef.col = "black")
# Chunk 8: regresiones
LinRegA = lm(Democracy ~ ., data = dataidx[,c(3:5)])
LinRegB = lm(Democracy ~ ., data = dataidx[,c(2:5)])
# Chunk 9: regresionesPlot
stargazer(LinRegA,LinRegB,
title = "Modelos de Regresión",
label = "regresiones")
# Chunk 10: getMap
library(rgdal)
folder='world_map'
file='world_map.shp'
mapaFile=file.path(folder,file)
colRegs <- rgdal::readOGR(mapaFile,stringsAsFactors=F)
colRegsIdx=merge(colRegs,dataidx, by.x='NAME', by.y='Country',all.x=F)
# Chunk 11
dimensions=c("NAME","EconomicFreedom","PressFreedom","Democracy")
library(cluster)
dataCluster=colRegsIdx@data[,c(dimensions)]
dataCluster[,-1]=lapply(dataCluster[,-1],as.ordered)
row.names(dataCluster)=dataCluster$NAME
dist=daisy(dataCluster[,-1],metric = "gower")
pam_fit <- pam(dist, diss = TRUE, k = 3)
clusters=as.data.frame(pam_fit$clustering)
clusters$NAME=row.names(clusters)
names(clusters)=c('cluster','NAME')
colRegsIdx=merge(colRegsIdx,clusters, by='NAME',all.x=F)
# Chunk 12: plotMap1
library(RColorBrewer)
library(classInt)
varToPLot=colRegsIdx$cluster
numberOfClasses = length(unique(varToPLot))
colorForScale='Set2'
paleta = brewer.pal(numberOfClasses, colorForScale)
plot(colRegs,col='grey',border=0)
plot(colRegsIdx, col = paleta[varToPLot],border=F,add=T)
legend('left', legend = c("MEDIUM","LOW","UP"), # third change
fill = paleta, # fourth change
cex = 0.6,
bty = "n",
title="conglomerado")
# Chunk 1: getData
# carga de datos
filename="indexes.csv"
dataidx=read.csv(filename, stringsAsFactors = FALSE)
# previsión:
level5=c("muy malo","malo","medio","bueno","muy bueno")
level4=c("muy malo","malo","bueno","muy bueno")
level3=c("muy malo","medio","muy bueno")
# Chunk 2
library(reporttools)
library(xtable)
titulo <- "Tablas de Frecuencia de la variables en estudio"
tableNominal(vars = dataidx[, c(2:5)],
cap = titulo, vertical = FALSE,
lab ="Tfrecuencias",
caption.placement = "top",
font.size = "normalsize",
add.to.row = list(pos = list(0),
command = "\\hline"))
# Chunk 3: barplots
par(mfrow=c(2,2))
demoTable=table(dataidx[,5])
names(demoTable)=level4
demoTableRel=round(prop.table(demoTable)*100,1)
title='Democracia'
paleta='red'
demoTableRelPlot=barplot(demoTableRel,main=title,
col=paleta,ylim = c(0,100),
ylab = "%")
###
ecoTable=table(dataidx[,3])
names(ecoTable)=level5
ecoTableRel=round(prop.table(ecoTable)*100,1)
title='Libertad Económica'
paleta='red'
barplot(ecoTableRel,main=title,
col=paleta,ylim = c(0,100),
ylab = "%")
#####
worldTable=table(dataidx[,2])
names(worldTable)=level3
worldTableRel=round(prop.table(worldTable)*100,1)
title='Libertad en el Mundo'
paleta='red'
barplot(worldTableRel,main=title,
col=paleta,ylim = c(0,100),
ylab = "%")
####
pressTable=table(dataidx[,4])
names(pressTable)=level5
pressTableRel=round(prop.table(pressTable)*100,1)
title='Libertad de Prensa'
paleta='red'
barplot(pressTableRel,main=title,
col=paleta,ylim = c(0,100),
ylab = "%",las=2)
# Chunk 4: summary
library(stargazer)
vars1 <- dataidx[, c(2:5)]
stargazer(vars1,title = "Medidas estadísticas", label = "stats",summary.stat = c("n", "median"))
# Chunk 5: corrDem
explanans=names(dataidx)[c(2:4)]
corrDem=cor(dataidx[,5],dataidx[,explanans],
use = "na.or.complete")
stargazer(corrDem, title="Correlación de Democracia con las demás variables",label = "corrDem")
# Chunk 6: corrTableX
corrTableX=round(cor(dataidx[explanans],
use = "na.or.complete"),2)
corrTableX_copy=corrTableX
# Hide upper triangle
corrTableX[upper.tri(corrTableX)]<-""
stargazer(corrTableX, title="Correlación entre variables independientes",label = 'corrTableX')
# Chunk 7: corrPlotX
library(corrplot)
corrplot(corrTableX_copy, type = "lower", diag = F,
addCoef.col = "black")
# Chunk 8: regresiones
LinRegA = lm(Democracy ~ ., data = dataidx[,c(3:5)])
LinRegB = lm(Democracy ~ ., data = dataidx[,c(2:5)])
# Chunk 9: regresionesPlot
stargazer(LinRegA,LinRegB,
title = "Modelos de Regresión",
label = "regresiones")
# Chunk 10: getMap
library(rgdal)
folder='world_map'
file='world_map.shp'
mapaFile=file.path(folder,file)
colRegs <- rgdal::readOGR(mapaFile,stringsAsFactors=F)
colRegsIdx=merge(colRegs,dataidx, by.x='NAME', by.y='Country',all.x=F)
# Chunk 11
dimensions=c("NAME","EconomicFreedom","PressFreedom","Democracy")
library(cluster)
dataCluster=colRegsIdx@data[,c(dimensions)]
dataCluster[,-1]=lapply(dataCluster[,-1],as.ordered)
row.names(dataCluster)=dataCluster$NAME
dist=daisy(dataCluster[,-1],metric = "gower")
pam_fit <- pam(dist, diss = TRUE, k = 3)
clusters=as.data.frame(pam_fit$clustering)
clusters$NAME=row.names(clusters)
names(clusters)=c('cluster','NAME')
colRegsIdx=merge(colRegsIdx,clusters, by='NAME',all.x=F)
# Chunk 12: plotMap1
library(RColorBrewer)
library(classInt)
varToPLot=colRegsIdx$cluster
numberOfClasses = length(unique(varToPLot))
colorForScale='Set2'
paleta = brewer.pal(numberOfClasses, colorForScale)
plot(colRegs,col='grey',border=0)
plot(colRegsIdx, col = paleta[varToPLot],border=F,add=T)
legend('left', legend = c("MEDIUM","LOW","UP"), # third change
fill = paleta, # fourth change
cex = 0.6,
bty = "n",
title="conglomerado")
# Chunk 1: getData
# carga de datos
filename="indexes.csv"
dataidx=read.csv(filename, stringsAsFactors = FALSE)
# previsión:
level5=c("muy malo","malo","medio","bueno","muy bueno")
level4=c("muy malo","malo","bueno","muy bueno")
level3=c("muy malo","medio","muy bueno")
# Chunk 2
library(reporttools)
library(xtable)
titulo <- "Tablas de Frecuencia de la variables en estudio"
tableNominal(vars = dataidx[, c(2:5)],
cap = titulo, vertical = FALSE,
lab ="Tfrecuencias",
caption.placement = "top",
font.size = "normalsize",
add.to.row = list(pos = list(0),
command = "\\hline"))
# Chunk 3: barplots
par(mfrow=c(2,2))
demoTable=table(dataidx[,5])
names(demoTable)=level4
demoTableRel=round(prop.table(demoTable)*100,1)
title='Democracia'
paleta='red'
demoTableRelPlot=barplot(demoTableRel,main=title,
col=paleta,ylim = c(0,100),
ylab = "%")
###
ecoTable=table(dataidx[,3])
names(ecoTable)=level5
ecoTableRel=round(prop.table(ecoTable)*100,1)
title='Libertad Económica'
paleta='red'
barplot(ecoTableRel,main=title,
col=paleta,ylim = c(0,100),
ylab = "%")
#####
worldTable=table(dataidx[,2])
names(worldTable)=level3
worldTableRel=round(prop.table(worldTable)*100,1)
title='Libertad en el Mundo'
paleta='red'
barplot(worldTableRel,main=title,
col=paleta,ylim = c(0,100),
ylab = "%")
####
pressTable=table(dataidx[,4])
names(pressTable)=level5
pressTableRel=round(prop.table(pressTable)*100,1)
title='Libertad de Prensa'
paleta='red'
barplot(pressTableRel,main=title,
col=paleta,ylim = c(0,100),
ylab = "%",las=2)
# Chunk 4: summary
library(stargazer)
vars1 <- dataidx[, c(2:5)]
stargazer(vars1,title = "Medidas estadísticas", label = "stats",summary.stat = c("n", "median"))
# Chunk 5: corrDem
explanans=names(dataidx)[c(2:4)]
corrDem=cor(dataidx[,5],dataidx[,explanans],
use = "na.or.complete")
stargazer(corrDem, title="Correlación de Democracia con las demás variables",label = "corrDem")
# Chunk 6: corrTableX
corrTableX=round(cor(dataidx[explanans],
use = "na.or.complete"),2)
corrTableX_copy=corrTableX
# Hide upper triangle
corrTableX[upper.tri(corrTableX)]<-""
stargazer(corrTableX, title="Correlación entre variables independientes",label = 'corrTableX')
# Chunk 7: corrPlotX
library(corrplot)
corrplot(corrTableX_copy, type = "lower", diag = F,
addCoef.col = "black")
# Chunk 8: regresiones
LinRegA = lm(Democracy ~ ., data = dataidx[,c(3:5)])
LinRegB = lm(Democracy ~ ., data = dataidx[,c(2:5)])
# Chunk 9: regresionesPlot
stargazer(LinRegA,LinRegB,
title = "Modelos de Regresión",
label = "regresiones")
# Chunk 10: getMap
library(rgdal)
folder='world_map'
file='world_map.shp'
mapaFile=file.path(folder,file)
colRegs <- rgdal::readOGR(mapaFile,stringsAsFactors=F)
# Chunk 12: mergeMap
colRegsIdx=merge(colRegs,dataidx, by.x='NAME', by.y='Country',all.x=F)
# Chunk 14: plotMap1
plot(colRegs,col='black')
plot(colRegsIdx,col='pink',border='grey',add=T)
\usepackage[utf8]{inputenc}
\usepackage{longtable}
\usepackage{authblk}
\usepackage{adjustbox}
\usepackage[utf8]{inputenc}
\usepackage{longtable}
\usepackage{authblk}
\usepackage{adjustbox}
# carga de datos
filename="indexes.csv"
dataidx=read.csv(filename, stringsAsFactors = FALSE)
# previsión:
level5=c("muy malo","malo","medio","bueno","muy bueno")
level4=c("muy malo","malo","bueno","muy bueno")
level3=c("muy malo","medio","muy bueno")
library(reporttools)
library(xtable)
titulo <- "Tablas de Frecuencia de la variables en estudio"
tableNominal(vars = dataidx[, c(2:5)],
cap = titulo, vertical = FALSE,
lab ="Tfrecuencias",
caption.placement = "top",
font.size = "normalsize",
add.to.row = list(pos = list(0),
command = "\\hline"))
# Chunk 1: getData
# carga de datos
filename="colombia.csv"
colb=read.csv(filename, stringsAsFactors = FALSE)
colb$Poblacion.Cabecera= colb$Poblacion.Cabecera*1
colb$Poblacion.Resto=colb$Poblacion.Resto*1
str(colb)
# Chunk 2: corrTableX
## estadisticos
# nos interesa IDH, y poblacion cabecera y poblacion resto
# no se puede sacar tabla de frecuencia,
# solo estadisticos:
summary(colb)
# dado el sesgo de las pobaciones,
# podriamos transformarla para que se acerque a la
# normalidad
colb$cabeLog=log(colb$Poblacion.Cabecera)
colb$restoLog=log(colb$Poblacion.Resto)
# Exploracion Bivariada --------------------------------------------------
# En este trabajo estamos interesados en el impacto de
# la poblacion en el el IDH, veamos IDH con cada uno:
explanans=names(colb)[c(7:8)] # usando las logs
corrDem=cor(colb$IDH,colb[,explanans],
use = "na.or.complete")
corrDem
# y la correlación entre las variables independientes:
corrTableX=round(cor(colb[,explanans],
use = "na.or.complete"),2)
corrTableX_copy=corrTableX
corrTableX[upper.tri(corrTableX)]<-""
#ver:
corrTableX
# Chunk 3: getMap
library(rgdal)
folder='COL_maps'
file='COL_adm1.shp'
mapaFile=file.path(folder,file)
mapCol <- rgdal::readOGR(mapaFile,stringsAsFactors=F)
# lo tenemos:
plot(mapCol)
# veamos que variables hay:
head(mapCol@data)
# Chunk 5: mergeMap
sub_colb=colb[,c(1,6,7,8)]
mapCol_idh=merge(mapCol,sub_colb, by.x='NAME_1', by.y='DepartamentoNorm',all.x=F)
nrow(mapCol_idh)
# Chunk 7: clust
names(mapCol_idh)
# nombre de la variables que usaré:
dimensions=c("NAME_1","IDH","cabeLog","restoLog")
# creo un nuevo data frame con esas:
dataCluster=mapCol_idh@data[,c(dimensions)]
# como la data es numerica la normalizo (menos la column 1):
dataCluster[,-1]=scale(dataCluster[,-1])
## APLICANDO TECNICA KMEANS
# calculo 3 clusters
resultado=kmeans(dataCluster[,-1],3)
#creo data frame con los clusters:
clusters=as.data.frame(resultado$cluster)
# añado columna con nombre de regiones
clusters$NAME_1=dataCluster$NAME_1
names(clusters)=c('cluster','NAME_1')
#hago el merge hacia el mapa:
mapCol_idh=merge(mapCol_idh,clusters, by='NAME_1',all.x=F)
# lo tengo?
names(mapCol_idh)
# Chunk 8: plotMap0
library(RColorBrewer)
library(classInt)
#variable a colorear
varToPLot=mapCol_idh$cluster
# decidir color:
unique(varToPLot)
aggregate(mapCol_idh@data[,c(10,11,12)],
by=list(mapCol_idh@data$cluster),FUN=mean)
#preparo colores
numberOfClasses = length(unique(varToPLot))
colorForScale='Blues'
paleta = brewer.pal(numberOfClasses,colorForScale)
# grafico mapa basico
plot(mapCol,col='grey',border=0)
# grafico mapa cluster
plot(mapCol_idh, col = paleta[varToPLot],border=F,add=T)
legend('left', legend = c("LOW","UP","MEDIUM"),
fill = paleta,
cex = 0.6,
bty = "n",
title="conglomerado")
setwd("~/REPOSITORIOS/ProyectoFinalHerramientas")
# Chunk 1: getData
# carga de datos
filename="colombia.csv"
colb=read.csv(filename, stringsAsFactors = FALSE)
colb$Poblacion.Cabecera= colb$Poblacion.Cabecera*1
colb$Poblacion.Resto=colb$Poblacion.Resto*1
str(colb)
# Chunk 2: corrTableX
## estadisticos
# nos interesa IDH, y poblacion cabecera y poblacion resto
# no se puede sacar tabla de frecuencia,
# solo estadisticos:
summary(colb)
# dado el sesgo de las pobaciones,
# podriamos transformarla para que se acerque a la
# normalidad
colb$cabeLog=log(colb$Poblacion.Cabecera)
colb$restoLog=log(colb$Poblacion.Resto)
# Exploracion Bivariada --------------------------------------------------
# En este trabajo estamos interesados en el impacto de
# la poblacion en el el IDH, veamos IDH con cada uno:
explanans=names(colb)[c(7:8)] # usando las logs
corrDem=cor(colb$IDH,colb[,explanans],
use = "na.or.complete")
corrDem
# y la correlación entre las variables independientes:
corrTableX=round(cor(colb[,explanans],
use = "na.or.complete"),2)
corrTableX_copy=corrTableX
corrTableX[upper.tri(corrTableX)]<-""
#ver:
corrTableX
# Chunk 3: getMap
library(rgdal)
folder='COL_maps'
file='COL_adm1.shp'
mapaFile=file.path(folder,file)
mapCol <- rgdal::readOGR(mapaFile,stringsAsFactors=F)
# lo tenemos:
plot(mapCol)
# veamos que variables hay:
head(mapCol@data)
# Chunk 5: mergeMap
#primero ordenas la lista en orden alfabetico
sub_colb=colb[,c(1,6,7,8)]
sub_colb=sub_colb[order(sub_colb$DepartamentoNorm),]
#luego agrego una columna ID para identificarse en vez de nombres
nueva.col<-c(seq(1:32))
sub_colb$ID<-nueva.col
mapCol_idh=merge(mapCol,sub_colb, by.x='ID_1', by.y='ID',all.x=F)
nrow(mapCol_idh)
# Chunk 7: clust
names(mapCol_idh)
# nombre de la variables que usaré:
dimensions=c("DepartamentoNorm","IDH","cabeLog","restoLog")
# creo un nuevo data frame con esas:
dataCluster=mapCol_idh@data[,c(dimensions)]
# como la data es numerica la normalizo (menos la column 1):
dataCluster[,-1]=scale(dataCluster[,-1])
## APLICANDO TECNICA KMEANS
# calculo 3 clusters
resultado=kmeans(dataCluster[,-1],3)
#creo data frame con los clusters:
clusters=as.data.frame(resultado$cluster)
# añado columna con nombre de regiones
clusters$DepartamentoNorm=dataCluster$DepartamentoNorm
names(clusters)=c('cluster','DepartamentoNorm')
#hago el merge hacia el mapa:
mapCol_idh=merge(mapCol_idh,clusters, by='DepartamentoNorm',all.x=F)
# lo tengo?
names(mapCol_idh)
# Chunk 8: plotMap0
library(RColorBrewer)
library(classInt)
#variable a colorear
varToPLot=mapCol_idh$cluster
# decidir color:
unique(varToPLot)
aggregate(mapCol_idh@data[,c(11,12,13)],
by=list(mapCol_idh@data$cluster),FUN=mean)
#preparo colores
numberOfClasses = length(unique(varToPLot))
colorForScale='Blues'
paleta = brewer.pal(numberOfClasses,colorForScale)
# grafico mapa basico
plot(mapCol,col='grey',border=0)
# grafico mapa cluster
plot(mapCol_idh, col = paleta[varToPLot],border=T,add=T)
legend('left', legend = c("BAJO","MEDIO","ALTO"),
fill = paleta,
cex = 0.8,
bty = "n",
title="  NIVEL DE IMPACTO")
=======
setwd("~/Documents/Repositorios/ProyectoFinalHerramientas")
>>>>>>> c41ce278211127108729943656bea93e4e66b2dd
setwd("~/Documents/Repositorios/ProyectoFinalHerramientas")
